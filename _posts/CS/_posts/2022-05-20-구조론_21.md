---
layout: post
title: 컴퓨터 구조론 - 21
categories: Structure
tags: [CS, Computer Structure]
---

# 구조론 - 21

{:toc}

### Cache Misses

##### Instruction Fetch

1. PC값을 캐시로 보냄
2. 있는 지 확인, tag/valid 사용
3. Hit이면 명령어 반환
4. Miss이면 Stall CPU
5. Fetch Cache Block From Memory
6. 캐시 작성
7. Instruction Fetch 재시작

- 데이터 Read도 이와 유사

##### Write-Through

- 캐시에만 작성하면 메모리의 값과 다른 값이 유지됨
  - 일관성 해침
- Write Through == 메모리에도 같이 작성하자
- 시간은 오래 걸림
- ex. cpi = 1, 10%가 store, store는 100cycle
  - 1 + 0.1 \* 100 = 11

##### Write Buffer

- Write할 때 CPU가 대기하지 않고 계속 작업
  - 버퍼에만 작성
- Buffer가 알아서 데이터를 작성
- Buffer가 무한하지 않기 때문에 꽉 차면 Stall 발생

##### Write Back

- data write에서 HIT이면 캐시에만 작성
- 해당 Block이 메모리와 동일한 지 저장하는 Dirty Bit 추가
  - 수정되지 않았으면 0
- 해당 Block이 교체될 때 메모리에 작성
  - 이 때 write buffer 사용 가능

##### Write Allocation

- write할 데이터가 캐시에 있으면(HIT) write back 실행
- miss이면?
- Write Allocation == write를 할 데이터를 캐시에 불러와서 작성
- No Write Allocation == 그냥 메모리에 작성
  - aka Write Around

##### Ex. Intrinsity FastMATH

- 12 stage Pipeline
- Instruction cache, Data cache 별도
  - 각 16KB, 256 Block x 16 Words
- miss rage
  - i-cache: 0.4%
  - d-cache: 11.4%
  - avg: 3.2%
  - i캐시를 더 많이 사용하기 때문

### Cache Performance

<img src="https://github.com/L-Hyun/L-Hyun.github.io/blob/main/assets/CS/21-1.png?raw=true" />

##### Ex.

- I-cache miss rate: 2%
- D-cache miss rate: 4%
- Miss Penalty: 100 cycles
- Base CPI = 2
- 36% of Load/Store

---

<img src="https://github.com/L-Hyun/L-Hyun.github.io/blob/main/assets/CS/21-2.png?raw=true" />

##### 연습문제

<img src="https://github.com/L-Hyun/L-Hyun.github.io/blob/main/assets/CS/21-3.png?raw=true" />

##### Average Access Time

- AMAT = Hit time + Miss Rate x Miss Penalty
  - Avg Memory Access Time

### Performance Summary

- Large Miss Rate, Miss Penalty는 CPI를 감소시킴
  - 결국 캐시 Hit가 얼마나 되는 지가 전체 성능을 좌우함
- CPU Clock Rate가 증가할수록 Miss Penalty 증가
- 캐시 성능이 제일 중요
